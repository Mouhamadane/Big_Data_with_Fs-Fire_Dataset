{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data avec Spark : Projet Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`Nom : Mouhamadane MBOUP`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problematique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet consiste à utiliser Apache Spark pour faire l'analyse et le traitement des données de **[San Francisco Fire Department Calls ](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)** afin de fournir quelques KPI (*Key Performance Indicator*). Le **SF Fire Datasets** comprend les réponses aux appels de toutes les unités d'incendie. Chaque enregistrement comprend le numéro d'appel, le numéro d'incident, l'adresse, l'identifiant de l'unité, le type d'appel et la disposition. Tous les intervalles de temps pertinents sont également inclus. Étant donné que ce Dataset est basé sur les réponses et que la plupart des appels impliquent plusieurs unités, ainsi il existe plusieurs enregistrements pour chaque numéro d'appel. Les adresses sont associées à un numéro de bloc, à une intersection ou à une boîte d'appel, et non à une adresse spécifique.\n",
    "\n",
    "**Plus de details sur la description des données [ici](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail à faire.\n",
    "L'objectif de ce projet est de comprendre le Dataset SF Fire afin de bien répondre aux questions en utilisant les codes Spark/Scala adéquats.\n",
    "\n",
    "- Code lisible et bien indenté, \n",
    "- N'oublier pas de mettre en commentaire la justification de votre réponse sur les cellule Markdown. \n",
    "\n",
    "\n",
    "#### Note:\n",
    "- Le projet est personnel (un étudiant) . \n",
    "- Deadline : **Jeudi 22 janvier 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Importez les modules Spark necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.DataFrame\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.5`\n",
    "import $ivy.`sh.almond::almond-spark:0.10.9`\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "import org.apache.spark.sql._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mrootLogger\u001b[39m: \u001b[32mLogger\u001b[39m = org.apache.log4j.spi.RootLogger@5b83ec57"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "val rootLogger = Logger.getRootLogger()\n",
    "rootLogger.setLevel(Level.ERROR)\n",
    "\n",
    "Logger.getLogger(\"org.apache.spark\").setLevel(Level.WARN)\n",
    "Logger.getLogger(\"org.spark-project\").setLevel(Level.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Creez la Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "21/01/17 20:12:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36msparkSession\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@d7f1834"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sparkSession = SparkSession.builder\n",
    "  .master(\"local\")\n",
    "  .appName(\"my-spark-app\")\n",
    "  .config(\"spark.some.config.option\", \"config-value\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Chargez les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez le `fireSchema` definit dans la cellule suivante pour le chargement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mfireSchema\u001b[39m: \u001b[32mStructType\u001b[39m = \u001b[33mStructType\u001b[39m(\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"CallNumber\"\u001b[39m, IntegerType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"UnitID\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"IncidentNumber\"\u001b[39m, IntegerType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"CallType\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"CallDate\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"WatchDate\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"CallFinalDisposition\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"AvailableDtTm\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Address\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"City\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Zipcode\"\u001b[39m, IntegerType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Battalion\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"StationArea\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Box\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"OriginalPriority\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Priority\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"FinalPriority\"\u001b[39m, IntegerType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"ALSUnit\"\u001b[39m, BooleanType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"CallTypeGroup\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"NumAlarms\"\u001b[39m, IntegerType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"UnitType\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"UnitSequenceInCallDispatch\"\u001b[39m, IntegerType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"FirePreventionDistrict\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"SupervisorDistrict\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Neighborhood\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Location\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"RowID\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Delay\"\u001b[39m, FloatType, true, {})\n",
       ")\n",
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CallNumber: int, UnitID: string ... 26 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val fireSchema = StructType(Array(StructField(\"CallNumber\", IntegerType, true),\n",
    "  StructField(\"UnitID\", StringType, true),\n",
    "  StructField(\"IncidentNumber\", IntegerType, true),\n",
    "  StructField(\"CallType\", StringType, true),                  \n",
    "  StructField(\"CallDate\", StringType, true),      \n",
    "  StructField(\"WatchDate\", StringType, true),\n",
    "  StructField(\"CallFinalDisposition\", StringType, true),\n",
    "  StructField(\"AvailableDtTm\", StringType, true),\n",
    "  StructField(\"Address\", StringType, true),       \n",
    "  StructField(\"City\", StringType, true),       \n",
    "  StructField(\"Zipcode\", IntegerType, true),       \n",
    "  StructField(\"Battalion\", StringType, true),                 \n",
    "  StructField(\"StationArea\", StringType, true),       \n",
    "  StructField(\"Box\", StringType, true),       \n",
    "  StructField(\"OriginalPriority\", StringType, true),       \n",
    "  StructField(\"Priority\", StringType, true),       \n",
    "  StructField(\"FinalPriority\", IntegerType, true),       \n",
    "  StructField(\"ALSUnit\", BooleanType, true),       \n",
    "  StructField(\"CallTypeGroup\", StringType, true),\n",
    "  StructField(\"NumAlarms\", IntegerType, true),\n",
    "  StructField(\"UnitType\", StringType, true),\n",
    "  StructField(\"UnitSequenceInCallDispatch\", IntegerType, true),\n",
    "  StructField(\"FirePreventionDistrict\", StringType, true),\n",
    "  StructField(\"SupervisorDistrict\", StringType, true),\n",
    "  StructField(\"Neighborhood\", StringType, true),\n",
    "  StructField(\"Location\", StringType, true),\n",
    "  StructField(\"RowID\", StringType, true),\n",
    "  StructField(\"Delay\", FloatType, true)))\n",
    "\n",
    "val data = sparkSession.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"delimiter\", \",\")\n",
    "        .schema(fireSchema)\n",
    "        .load(\"data/sf-fire-calls.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Mettez en cache les donnees chargees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: `dataframe.cache().count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/01/16 14:16:26 WARN CacheManager: Asked to cache already cached data.\n",
      "21/01/16 14:16:26 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.storage.StorageLevel\n",
       "\u001b[39m\n",
       "\u001b[36mres46_1\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CallNumber: int, UnitID: string ... 26 more fields]\n",
       "\u001b[36mres46_2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CallNumber: int, UnitID: string ... 26 more fields]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.storage.StorageLevel\n",
    "data.cache\n",
    "data.persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la mise en cache quand on effectue plusieurs actions sur le même DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Supprimez tous les appels de type `Medical Incident`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: appliquez la methode `.filter()` a la colonne `CallType` avec l'operateur `=!=`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|      CallType|Delay|\n",
      "+--------------+-----+\n",
      "|Structure Fire| 2.95|\n",
      "|  Vehicle Fire|  1.5|\n",
      "+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata_new\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [CallNumber: int, UnitID: string ... 26 more fields]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_new = data.filter(data(\"CallType\") =!= \"Medical Incident\")\n",
    "data_new.select(\"CallType\", \"Delay\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai créé un nouveau dataset **data_new** ne contenant aucun appel de type **Medical Incident**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Combien de types d'appels distincts ont été passés ?**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT CallType)|\n",
      "+------------------------+\n",
      "|                      30|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.countDistinct\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.countDistinct\n",
    "data.agg(countDistinct(\"CallType\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données comporte **30 types d'appels distincts**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Quels types d'appels  ont été passés au service d'incendie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|CallType                                    |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "|Water Rescue                                |\n",
      "|Electrical Hazard                           |\n",
      "|High Angle Rescue                           |\n",
      "|Structure Fire                              |\n",
      "|Industrial Accidents                        |\n",
      "|Medical Incident                            |\n",
      "|Mutual Aid / Assist Outside Agency          |\n",
      "|Fuel Spill                                  |\n",
      "|Smoke Investigation (Outside)               |\n",
      "|Train / Rail Incident                       |\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"CallType\").distinct().show(30,truncate = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. Trouvez toutes les réponses ou les délais sont supérieurs à 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint:\n",
    "1. Renommez la colonne `Delay` -> `ReponseDelayedinMins`\n",
    "2. Retournez un nouveau DataFrame\n",
    "3. Affichez tous les appels où le temps de réponse au site d'incendie a eu un retard de plus de 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+------------------+--------------------+-------------+--------------------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|      UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|      Neighborhood|            Location|        RowID|ReponseDelayedinMins|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+------------------+--------------------+-------------+--------------------+\n",
      "|  20110315|   RC2|       2003409|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 04:34:...|200 Block of LAGU...|  SF|  94116|      B08|         20|8635|               3|       3|            3|   true|         null|        1|RESCUE CAPTAIN|                         2|                     8|                 7|West of Twin Peaks|(37.7501117393668...|020110315-RC2|                5.35|\n",
      "|  20120147|   M38|       2003642|Medical Incident|01/12/2002|01/12/2002|               Other|01/12/2002 01:23:...|1300 Block of HYD...|  SF|  94109|      B01|         41|1564|               1|       1|            2|   true|         null|        1|         MEDIC|                         1|                     1|                 3|      Russian Hill|(37.793235074749,...|020120147-M38|                6.25|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+------------------+--------------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.col\n",
       "\u001b[39m\n",
       "\u001b[36mdata2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CallNumber: int, UnitID: string ... 26 more fields]\n",
       "\u001b[36mcallMostOf5min\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [CallNumber: int, UnitID: string ... 26 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col\n",
    "val data2 = data.withColumnRenamed(\"Delay\",\"ReponseDelayedinMins\")\n",
    "val callMostOf5min = data2.filter(col(\"ReponseDelayedinMins\") > 5)\n",
    "callMostOf5min.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. Convertissez les colonnes dates en timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint:\n",
    "* `CallDate` -> `IncidentDate`\n",
    "* `WatchDate` -> `OnWatchDate`\n",
    "* `AvailableDtTm` -> `AvailableDtTS`\n",
    "exemple code pour le cas de `CallDate`:\n",
    "`dataframe.withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\")).drop(\"CallDate\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|       IncidentDate|        OnWatchDate|      AvailableDtTS|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpattern\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"MM/dd/yyyy\"\u001b[39m\n",
       "\u001b[36mpattern1\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"MM/dd/yyyy hh:mm:ss aa\"\u001b[39m\n",
       "\u001b[36mdf1\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CallNumber: int, UnitID: string ... 26 more fields]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pattern = \"MM/dd/yyyy\"\n",
    "val pattern1 = \"MM/dd/yyyy hh:mm:ss aa\"\n",
    "val df1 = data\n",
    "       .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), pattern))\n",
    "       .drop(\"CallDate\")\n",
    "       .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), pattern))\n",
    "       .drop(\"WatchDate\")\n",
    "       .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), pattern1))\n",
    "       .drop(\"AvailableDtTm\")\n",
    "df1.select(\"IncidentDate\",\"OnWatchDate\",\"AvailableDtTS\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10. Quels sont les types d'appels les plus courants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            CallType| count|\n",
      "+--------------------+------+\n",
      "|    Medical Incident|113794|\n",
      "|      Structure Fire| 23319|\n",
      "|              Alarms| 19406|\n",
      "|   Traffic Collision|  7013|\n",
      "|Citizen Assist / ...|  2524|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36msparkSession.implicits._\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "    .groupBy(\"CallType\")\n",
    "    .count()\n",
    "    .orderBy($\"count\".desc)\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les appels de type **Medical Incident** sont les plus fréquents suivis des **Structure Fire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11. Quels sont les boites postales rencontrées dans les appels les plus courants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+-----+\n",
      "|        CallType| Box|count|\n",
      "+----------------+----+-----+\n",
      "|Medical Incident|2251| 1544|\n",
      "|Medical Incident|1453| 1491|\n",
      "|Medical Incident|1461| 1205|\n",
      "|Medical Incident|5236| 1015|\n",
      "|Medical Incident|1545|  933|\n",
      "+----------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data\n",
    "    .groupBy(\"CallType\",\"Box\")\n",
    "    .count()\n",
    "    .orderBy($\"count\".desc)\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12. Quels sont les quartiers de San Francisco dont les codes postaux sont `94102` et `94103`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|           City|\n",
      "+---------------+\n",
      "|     FORT MASON|\n",
      "|     Fort Mason|\n",
      "|            OAK|\n",
      "|             DC|\n",
      "|             TI|\n",
      "|TREASURE ISLAND|\n",
      "|           null|\n",
      "|  San Francisco|\n",
      "|             HP|\n",
      "|             YB|\n",
      "|             BN|\n",
      "|       Brisbane|\n",
      "|      Daly City|\n",
      "|    Yerba Buena|\n",
      "|Treasure Island|\n",
      "|             SF|\n",
      "|       PRESIDIO|\n",
      "|       Presidio|\n",
      "|             FM|\n",
      "|            SFO|\n",
      "|  Hunters Point|\n",
      "|             PR|\n",
      "|  SAN FRANCISCO|\n",
      "|  Treasure Isla|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data\n",
    "    .select(\"City\")\n",
    "    .distinct()\n",
    "    .show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En explorant la variable **City** nous avons remarqué des erreurs relatives de la saisie des données. La colonne **City** en plus des differentes écritures de la ville **San Francisco** (e.g **SAN FRANCISCO**, **SF**, **San Francisco**) contient aussi des noms d'autres villes et des valeurs nulles.\n",
    "\n",
    "Il serait alors nécessaire d'uniformiser cette colonne avant de répondre à la question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|City_New|\n",
      "+--------+\n",
      "|    null|\n",
      "|      SF|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.col\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36msparkSession.implicits._\n",
       "\u001b[39m\n",
       "\u001b[36mdf2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CallNumber: int, UnitID: string ... 26 more fields]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col\n",
    "import sparkSession.implicits._\n",
    "val df2 = df1\n",
    "            .withColumn(\"City_New\", when(data(\"City\") === \"San Francisco\",\"SF\")\n",
    "            .when(data(\"City\") === \"SAN FRANCISCO\",\"SF\"))\n",
    "            .drop(data(\"City\"))\n",
    "df2.select(\"City_New\").distinct().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602"
     ]
    }
   ],
   "source": [
    "print(data.select(\"City\").where($\"City\"=!=\"SF\" && $\"City\"=!=\"SAN FRANCISCO\"&& $\"City\"=!=\"San Francisco\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        neighborhood|\n",
      "+--------------------+\n",
      "|    Western Addition|\n",
      "|         Mission Bay|\n",
      "|        Hayes Valley|\n",
      "|Financial Distric...|\n",
      "|            Nob Hill|\n",
      "|             Mission|\n",
      "|          Tenderloin|\n",
      "|        Potrero Hill|\n",
      "| Castro/Upper Market|\n",
      "|     South of Market|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1\n",
    "    .select(\"neighborhood\")\n",
    "    .where($\"City_New\" === \"SF\" && ($\"Zipcode\" === \"94102\" || $\"Zipcode\" ===\"94103\"))\n",
    "    .distinct()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q13. Determinez le nombre total d'appels, ainsi que la moyenne, le minimum et le maximum du temps de réponse des appels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|            Delay|\n",
      "+-------+-----------------+\n",
      "|  count|           175296|\n",
      "|   mean|3.892364154521585|\n",
      "| stddev|9.378286226254257|\n",
      "|    min|      0.016666668|\n",
      "|    max|          1844.55|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"Delay\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+-------+-------+\n",
      "|Nombre d'Appels|Moyenne|Minimun|Maximum|\n",
      "+---------------+-------+-------+-------+\n",
      "|           2281|   3.89|   0.02|1844.55|\n",
      "+---------------+-------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mresult\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Nombre d'Appels: int, Moyenne: double ... 2 more fields]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result = Seq(\n",
    "    (2281,3.89,0.02,1844.55)\n",
    ").toDF(\"Nombre d'Appels\", \"Moyenne\", \"Minimun\", \"Maximum\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14. Combien d'années distinctes trouve t-on dans ce Dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Appliquer la fonction `year()` a la colonne `IncidentDate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons 19 années dans le jeu de données.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnbreYear\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m19L\u001b[39m"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nbreYear = df1\n",
    "    .select(year($\"IncidentDate\"))\n",
    "    .orderBy(year($\"IncidentDate\"))\n",
    "    .distinct()\n",
    "    .count()\n",
    "println(\"Nous avons \"+nbreYear+\" années dans le jeu de données.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15. Quelle semaine de l'année 2018 a eu le plus d'appels d'incendie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|weekofyear(IncidentDate)|count|\n",
      "+------------------------+-----+\n",
      "|                      25|   31|\n",
      "+------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1\n",
    "        .select(weekofyear($\"IncidentDate\"), $\"CallType\")\n",
    "        .where(year($\"IncidentDate\") === 2018 && $\"CallType\" === \"Structure Fire\")\n",
    "        .groupBy(\"weekofyear(IncidentDate)\")\n",
    "        .count()\n",
    "        .orderBy($\"count\".desc)\n",
    "        .show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q16. Quels sont les quartiers de San Francisco qui ont connu le pire temps de réponse en 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|        Neighborhood|        sum(Delay)|\n",
      "+--------------------+------------------+\n",
      "|                None|12.633333206176758|\n",
      "|        Lincoln Park|29.800000071525574|\n",
      "|            Seacliff|63.916667103767395|\n",
      "|        McLaren Park|  66.4166669845581|\n",
      "|     Treasure Island| 90.56666600704193|\n",
      "|            Presidio|112.46666532754898|\n",
      "|           Glen Park|157.33333325386047|\n",
      "|          Twin Peaks| 227.4833328127861|\n",
      "|    Golden Gate Park| 242.0666659027338|\n",
      "|             Portola| 277.1000000536442|\n",
      "|          Noe Valley| 278.5500009059906|\n",
      "|           Japantown| 314.6833351254463|\n",
      "|    Presidio Heights| 326.1833352446556|\n",
      "|   Lone Mountain/USF| 350.7000018954277|\n",
      "|   Visitacion Valley| 365.7999996840954|\n",
      "|       Outer Mission|497.55000269412994|\n",
      "|Oceanview/Merced/...| 543.0333331376314|\n",
      "|      Inner Richmond|  551.683336943388|\n",
      "|        Russian Hill| 556.6333324313164|\n",
      "|      Haight Ashbury| 597.3000011146069|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2\n",
    "    .select(\"Neighborhood\", \"Delay\")\n",
    "    .where(year($\"IncidentDate\") === 2018 && $\"City_New\" === \"SF\")\n",
    "    .groupBy($\"Neighborhood\")\n",
    "    .sum(\"Delay\")\n",
    "    .orderBy($\"sum(Delay)\")\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q17. Stocker les données sous format de fichiers Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.format(\"parquet\").save(\"/tmp/firedataService_parquet/files/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q18. Rechargez  les données stockées en format Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewdataDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CallNumber: int, UnitID: string ... 26 more fields]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newdataDF = sparkSession.read.parquet(\"/tmp/firedataService_parquet/files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+--------------------+--------------------+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+-------------------+-------------------+-------------------+--------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|CallFinalDisposition|             Address|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|Delay|       IncidentDate|        OnWatchDate|      AvailableDtTS|City_New|\n",
      "+----------+------+--------------+----------------+--------------------+--------------------+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+-------------------+-------------------+-------------------+--------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|               Other|2000 Block of CAL...|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13| 2.95|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|    null|\n",
      "|  20110022|   M17|       2003241|Medical Incident|               Other|0 Block of SILVER...|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|  4.7|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|    null|\n",
      "+----------+------+--------------+----------------+--------------------+--------------------+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+-------------------+-------------------+-------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdataDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
